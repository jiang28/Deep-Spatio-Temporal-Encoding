{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jiang28/Deep-Spatio-Temporal-Encoding/blob/master/Heavy_rain_risk_TransGcnRE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsodPZHaJ9qc",
        "outputId": "a0b81e9d-b975-4d1c-8782-68156538ce59"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AoW1WhKOl1f",
        "outputId": "f15a6513-4eba-41ad-fefd-166883695b86"
      },
      "source": [
        "cd drive/MyDrive/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpjabYjuOsyT",
        "outputId": "b277fab8-0817-439e-c264-2d36176146e3"
      },
      "source": [
        "PATH = '/content/drive/My Drive/'\n",
        "device = 'cuda'\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "  device = 'cuda'\n",
        "else:\n",
        "  device = 'cpu'\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from pandas import read_csv\n",
        "import pandas as pd\n",
        "\n",
        "output_window = 1\n",
        "\n",
        "def get_data():\n",
        "    data = []\n",
        "    features = []\n",
        "    location = []\n",
        "    label = []\n",
        "\n",
        "    # Load npy files\n",
        "    df = read_csv('Rain/data_total_prep2.csv', sep=',', header=None, low_memory=False, keep_default_na=False)\n",
        "\n",
        "    # Convert the DataFrame to a NumPy array\n",
        "    series = df.to_numpy()\n",
        "\n",
        "    for i in range(len(df)):\n",
        "        if i == 0:\n",
        "            continue\n",
        "\n",
        "        line = series[i][1:-14]\n",
        "        line = [float(_) if _ != '' else -1 for _ in line]\n",
        "        line = [int(j) for j in line]\n",
        "\n",
        "        data.append(line)\n",
        "\n",
        "        f = series[i][-14:-1]\n",
        "        f = [float(_) if _ != '' else -1 for _ in f]\n",
        "        f = [int(_) for _ in f]\n",
        "\n",
        "        features.append(f)\n",
        "\n",
        "        label.append(int(float(series[i][-1])))\n",
        "\n",
        "    data = np.asarray(data)\n",
        "    features = np.asarray(features)\n",
        "    label = np.asarray(label)\n",
        "\n",
        "    data_ = []\n",
        "    features_ = []\n",
        "    for i in range(len(data)):\n",
        "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "        x = data[i]\n",
        "        x = scaler.fit_transform(np.array(x).reshape(-1, 1)).reshape(-1)\n",
        "        data_.append(x)\n",
        "\n",
        "        features_.append(scaler.fit_transform(np.array(features[i]).reshape(-1, 1)).reshape(-1))\n",
        "\n",
        "    input_data = torch.FloatTensor(data_)\n",
        "    label = torch.FloatTensor(label)\n",
        "    features = torch.FloatTensor(features_)\n",
        "\n",
        "    # Shuffle the data before splitting into train and test sets\n",
        "    x_train, x_test, y_train, y_test, ftr_train, ftr_test = train_test_split(\n",
        "        input_data, label, features, test_size=0.3, random_state=42, shuffle=True)\n",
        "\n",
        "    return x_train, y_train, ftr_train, x_test, y_test, ftr_test, features\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    x_train, y_train, ftr_train, x_test, y_test, ftr_test, ftr_all = get_data()\n",
        "    print(x_train.shape)\n",
        "    print(x_train)\n",
        "    print(y_train.shape)\n",
        "    print(ftr_train.shape)\n",
        "\n",
        "    print(x_test.shape)\n",
        "    print(y_test.shape)\n",
        "    print(ftr_test.shape)\n",
        "\n",
        "    print(ftr_all.shape)\n",
        "\n",
        "    pass\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNrmFWkJUJmf",
        "outputId": "1f140852-8161-4dd3-9ec1-0c19b0aaf67d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([7000, 132])\n",
            "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.5036, 0.2628, 0.2555],\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.4706, 0.3235],\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 0.7534, 1.0000, 0.6027],\n",
            "        ...,\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 0.5574, 0.3770, 0.2869],\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 0.0139, 0.0278, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 0.9583, 0.5104, 0.4896]])\n",
            "torch.Size([7000])\n",
            "torch.Size([7000, 13])\n",
            "torch.Size([3000, 132])\n",
            "torch.Size([3000])\n",
            "torch.Size([3000, 13])\n",
            "torch.Size([10000, 13])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-4050b42d2562>:54: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  input_data = torch.FloatTensor(data_)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMiyIWx-Ouvq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2f391a6-563b-46f2-eda4-9f70a1ffcfce"
      },
      "source": [
        "#load data\n",
        "import torch\n",
        "def load_matrix():\n",
        "    matrix = []\n",
        "    with open('Rain/adj_matrix.txt', 'r') as f:\n",
        "        for i, line in enumerate(f):\n",
        "            row = [int(x) for x in line.split()]\n",
        "            matrix.append(row)\n",
        "\n",
        "    adj = torch.FloatTensor(matrix)\n",
        "    print('adj_matrix:', adj)\n",
        "    print('adj_matrix shape:', adj.shape)\n",
        "\n",
        "    return adj\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    adj = load_matrix()\n",
        "    print('Overall adj shape:', adj.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "adj_matrix: tensor([[0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
            "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 1., 0.]])\n",
            "adj_matrix shape: torch.Size([10000, 10000])\n",
            "Overall adj shape: torch.Size([10000, 10000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuXbZ6SFPrkV"
      },
      "source": [
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import argparse\n",
        "import sys\n",
        "import math\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.nn.modules.module import Module\n",
        "\n",
        "class GCNLayer(nn.Module):\n",
        "    def __init__(self, in_features, out_features, bias=True):\n",
        "        super(GCNLayer, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
        "        if bias:\n",
        "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
        "        self.weight.data.uniform_(-stdv, stdv)\n",
        "        if self.bias is not None:\n",
        "            self.bias.data.uniform_(-stdv, stdv)\n",
        "\n",
        "    def forward(self, input, adj):\n",
        "        support = torch.mm(input, self.weight)\n",
        "        output = torch.spmm(adj, support)\n",
        "        if self.bias is not None:\n",
        "            return output + self.bias\n",
        "        else:\n",
        "            return output\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + ' (' \\\n",
        "               + str(self.in_features) + ' -> ' \\\n",
        "               + str(self.out_features) + ')'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UD-bSFIWa8d"
      },
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        pe.requires_grad = True\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:x.size(0), :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbpuKtpLck5r"
      },
      "source": [
        "class TransGCN(nn.Module):\n",
        "    def __init__(self, input_size, feature_size=250,num_layers=1,dropout=0.1):\n",
        "        super(TransGCN, self).__init__()\n",
        "\n",
        "        #self.gc1 = GCNLayer(10, 10)\n",
        "        self.gc1 = GCNLayer(13, 13)\n",
        "        # self.gc2 = GCNLayer(5, 250)\n",
        "\n",
        "        self.src_mask = None\n",
        "        self.pos_encoder = PositionalEncoding(feature_size)\n",
        "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=feature_size, nhead=10, dropout=dropout)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
        "\n",
        "        self.decoder = nn.Linear(feature_size,1)\n",
        "        self.layer1 = nn.Linear(input_size, 200)\n",
        "        self.layer2 = nn.Linear(200, 100)\n",
        "        self.layer3 = nn.Linear(100, 1)\n",
        "\n",
        "        self.last_layer = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, src, ftr_all, adj, st_idx, ed_idx):\n",
        "        #gcn embedding loc information\n",
        "        #print('gcn input shape', ftr_all.shape)\n",
        "        gcn_output = self.gc1(ftr_all, adj)\n",
        "        #print('gcn output shape', gcn_output.shape)\n",
        "        gcn_output = F.relu(gcn_output)\n",
        "        # gcn_tmp = F.relu(self.gc1(ftr_all, adj))\n",
        "        # gcn_output = self.gc2(gcn_tmp, adj)\n",
        "\n",
        "        #transformer embedding time series data\n",
        "        if self.src_mask is None or self.src_mask.size(0) != len(src):\n",
        "            mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
        "            self.src_mask = mask\n",
        "\n",
        "        # junwei\n",
        "        #print('before pos', src.shape)\n",
        "        src = self.pos_encoder(src)\n",
        "        # junwei\n",
        "        #print('after pos', src.shape)\n",
        "\n",
        "        hidden = self.transformer_encoder(src,self.src_mask)\n",
        "\n",
        "        # junwei\n",
        "        #print('after encoder', src.shape)\n",
        "\n",
        "        gcn_output = gcn_output[st:ed]\n",
        "        gcn_output = torch.transpose(gcn_output, 0, 1)\n",
        "\n",
        "        gcn_output = torch.reshape(gcn_output, (gcn_output.shape[0], gcn_output.shape[1], 1))\n",
        "        gcn_output = gcn_output.expand(gcn_output.shape[0], gcn_output.shape[1], hidden.shape[2])\n",
        "\n",
        "        # concate gcn output to transformer output\n",
        "        output = torch.cat((hidden, gcn_output), 0)\n",
        "\n",
        "        output = self.decoder(output)\n",
        "\n",
        "        output = torch.squeeze(output)\n",
        "        output = output.transpose(0, 1)\n",
        "\n",
        "        #MLP prediction\n",
        "        output = self.layer1(output)\n",
        "        output = self.layer2(output)\n",
        "        output = self.layer3(output)\n",
        "\n",
        "        output = self.last_layer(output)\n",
        "        #print('output', output)\n",
        "        return output\n",
        "\n",
        "    def _generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "        return mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    arg_parser = argparse.ArgumentParser()\n",
        "    arg_parser.add_argument('--mode', choices=['train', 'infer'],\\\n",
        "      default='train',help='Run mode')\n",
        "    arg_parser.add_argument('--epoch', default='200', type=int)\n",
        "    arg_parser.add_argument('--batch_size', default='32', type=int)\n",
        "    args = arg_parser.parse_args(args=['--mode', 'train'])\n",
        "    args = arg_parser.parse_args(args=['--epoch', '200'])\n",
        "    #args = arg_parser.parse_args(args=['--epoch', '30'])\n",
        "    args = arg_parser.parse_args(args=['--batch_size', '32'])\n",
        "\n",
        "    X_train, y_train, FTR_train, X_test, y_test, FTR_test, FTR_all = get_data()\n",
        "\n",
        "    X_train = X_train.to(device)\n",
        "    y_train = y_train.to(device)\n",
        "    FTR_train = FTR_train.to(device)\n",
        "    X_test = X_test.to(device)\n",
        "    y_test = y_test.to(device)\n",
        "    FTR_test = FTR_test.to(device)\n",
        "\n",
        "    ftr_all = FTR_all.to(device)\n",
        "\n",
        "    adj = load_matrix().to(device)\n",
        "\n",
        "    model_path = PATH + 'MODEL1/model_trans_gcn.pt'\n",
        "    model = TransGCN(input_size=X_train.shape[1] + ftr_all.shape[1]).to(device)\n",
        "\n",
        "    loss_function = nn.BCELoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.02)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.98)\n",
        "\n",
        "    num_batch = int(len(y_train) / args.batch_size) + 1\n",
        "    num_batch_test = int(len(y_test) / args.batch_size) + 1\n",
        "\n",
        "    last_acc = 0.0\n",
        "\n",
        "    if args.mode == 'train':\n",
        "        for epoch in range(args.epoch):\n",
        "            model.train()\n",
        "            acc = []\n",
        "            total_loss = 0\n",
        "            acc_test = []\n",
        "\n",
        "            for i in range(num_batch):\n",
        "                sys.stdout.write('\\r{0}/{1}'.format(i, num_batch))\n",
        "                st = i * args.batch_size\n",
        "                ed = min((i + 1) * args.batch_size, len(y_train))\n",
        "\n",
        "                x = X_train[st:ed].transpose(0, 1).unsqueeze(-1)\n",
        "                label = y_train[st:ed]\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                output = model(x, ftr_all, adj, st, ed)\n",
        "                predict = torch.squeeze(output)\n",
        "\n",
        "                #loss = loss_function(predict+0.00001, label)\n",
        "                loss = loss_function(predict, label)\n",
        "\n",
        "                acc.append(torch.sum(predict.gt(0.5) == label))\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                total_loss += loss.item()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                model.eval()\n",
        "                for i in range(num_batch_test):\n",
        "                    st = i * args.batch_size\n",
        "                    ed = min((i + 1) * args.batch_size, len(y_test))\n",
        "\n",
        "                    x_test = X_test[st:ed].transpose(0, 1).unsqueeze(-1)\n",
        "                    label_test = y_test[st:ed]\n",
        "\n",
        "                    output_test = model(x_test, ftr_all, adj, X_train.shape[0] + st, X_train.shape[0] + ed)\n",
        "                    predict_test = torch.squeeze(output_test)\n",
        "                    acc_test.append(torch.sum(predict_test.gt(0.5) == label_test))\n",
        "\n",
        "            total_loss /= len(y_train)\n",
        "            acc = sum(acc) * 1.0 / len(y_train)\n",
        "            acc_test = sum(acc_test) * 1.0 / len(y_test)\n",
        "\n",
        "            if epoch % 10 == 0 or epoch == args.epoch - 1:\n",
        "                print('\\nEpoch: ', epoch)\n",
        "                print('\\nTraining set: Loss {0:.4f}. Acc {1:.4f}.\\nTest set: Acc {2:.4f}.'.format(total_loss, acc, acc_test))\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        if acc_test > last_acc:\n",
        "            torch.save(model.cpu(), model_path)\n",
        "            last_acc = acc_test\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfJ8JA1DnzH_",
        "outputId": "3992cf2f-dda0-4de6-faa3-5dcbf3c98683"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "adj_matrix: tensor([[0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
            "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 1., 0.]])\n",
            "adj_matrix shape: torch.Size([10000, 10000])\n",
            "218/219\n",
            "Epoch:  0\n",
            "\n",
            "Training set: Loss 0.0217. Acc 0.5204.\n",
            "Test set: Acc 0.5073.\n",
            "218/219\n",
            "Epoch:  10\n",
            "\n",
            "Training set: Loss 0.0147. Acc 0.7606.\n",
            "Test set: Acc 0.7553.\n",
            "218/219\n",
            "Epoch:  20\n",
            "\n",
            "Training set: Loss 0.0132. Acc 0.7916.\n",
            "Test set: Acc 0.7833.\n",
            "218/219\n",
            "Epoch:  30\n",
            "\n",
            "Training set: Loss 0.0125. Acc 0.8066.\n",
            "Test set: Acc 0.7990.\n",
            "218/219\n",
            "Epoch:  40\n",
            "\n",
            "Training set: Loss 0.0120. Acc 0.8194.\n",
            "Test set: Acc 0.8237.\n",
            "218/219\n",
            "Epoch:  50\n",
            "\n",
            "Training set: Loss 0.0116. Acc 0.8287.\n",
            "Test set: Acc 0.8283.\n",
            "218/219\n",
            "Epoch:  60\n",
            "\n",
            "Training set: Loss 0.0114. Acc 0.8359.\n",
            "Test set: Acc 0.8303.\n",
            "218/219\n",
            "Epoch:  70\n",
            "\n",
            "Training set: Loss 0.0110. Acc 0.8397.\n",
            "Test set: Acc 0.8367.\n",
            "218/219\n",
            "Epoch:  80\n",
            "\n",
            "Training set: Loss 0.0105. Acc 0.8484.\n",
            "Test set: Acc 0.8393.\n",
            "218/219\n",
            "Epoch:  90\n",
            "\n",
            "Training set: Loss 0.0103. Acc 0.8486.\n",
            "Test set: Acc 0.8443.\n",
            "218/219\n",
            "Epoch:  100\n",
            "\n",
            "Training set: Loss 0.0100. Acc 0.8577.\n",
            "Test set: Acc 0.8457.\n",
            "218/219\n",
            "Epoch:  110\n",
            "\n",
            "Training set: Loss 0.0098. Acc 0.8614.\n",
            "Test set: Acc 0.8470.\n",
            "218/219\n",
            "Epoch:  120\n",
            "\n",
            "Training set: Loss 0.0096. Acc 0.8676.\n",
            "Test set: Acc 0.8523.\n",
            "218/219\n",
            "Epoch:  130\n",
            "\n",
            "Training set: Loss 0.0093. Acc 0.8680.\n",
            "Test set: Acc 0.8517.\n",
            "218/219\n",
            "Epoch:  140\n",
            "\n",
            "Training set: Loss 0.0093. Acc 0.8697.\n",
            "Test set: Acc 0.8523.\n",
            "218/219\n",
            "Epoch:  150\n",
            "\n",
            "Training set: Loss 0.0092. Acc 0.8709.\n",
            "Test set: Acc 0.8603.\n",
            "218/219\n",
            "Epoch:  160\n",
            "\n",
            "Training set: Loss 0.0090. Acc 0.8777.\n",
            "Test set: Acc 0.8577.\n",
            "218/219\n",
            "Epoch:  170\n",
            "\n",
            "Training set: Loss 0.0088. Acc 0.8779.\n",
            "Test set: Acc 0.8613.\n",
            "218/219\n",
            "Epoch:  180\n",
            "\n",
            "Training set: Loss 0.0087. Acc 0.8783.\n",
            "Test set: Acc 0.8660.\n",
            "218/219\n",
            "Epoch:  190\n",
            "\n",
            "Training set: Loss 0.0086. Acc 0.8841.\n",
            "Test set: Acc 0.8610.\n",
            "218/219\n",
            "Epoch:  199\n",
            "\n",
            "Training set: Loss 0.0085. Acc 0.8799.\n",
            "Test set: Acc 0.8663.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfmLshoyMhZj"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    X_train, y_train, FTR_train, X_test, y_test, FTR_test, FTR_all = get_data()\n",
        "\n",
        "    num_batch = int(len(y_train)/args.batch_size) + 1\n",
        "\n",
        "    num_batch_test = int(len(y_test)/args.batch_size) + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8S537brJ5sl",
        "outputId": "24257197-b6b0-44be-e0c4-54adea408145"
      },
      "source": [
        "#TransGCN evaluation\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "model_path = PATH + 'MODEL1/model_trans_gcn.pt'\n",
        "model = torch.load(model_path)\n",
        "model.to(device)\n",
        "acc_test = []\n",
        "y_pred = []\n",
        "\n",
        "for i in range(num_batch_test):\n",
        "    st = i * args.batch_size\n",
        "    ed = min((i+1) * args.batch_size, len(y_test))\n",
        "\n",
        "    x_test = X_test[st:ed]\n",
        "    x_test = x_test.transpose(0, 1)\n",
        "    x_test = torch.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
        "    x_test = x_test.to(device)\n",
        "\n",
        "    label_test = y_test[st:ed]\n",
        "    label_test = label_test.to(device)\n",
        "\n",
        "    output_test = model(x_test, ftr_all, adj, X_train.shape[0] + st, X_train.shape[0] + ed)\n",
        "    predict_test = torch.squeeze(output_test)\n",
        "    #binary\n",
        "    y_pred += predict_test.gt(0.5)\n",
        "\n",
        "    #actual\n",
        "    #y_pred += predict_test\n",
        "\n",
        "y_pred = list(map(float, y_pred))\n",
        "y_pred = np.asarray(y_pred)\n",
        "y_pred = torch.FloatTensor(y_pred)\n",
        "\n",
        "# Convert y_pred to a NumPy array\n",
        "y_pred_np = np.array(y_pred)\n",
        "\n",
        "# Convert y_test to a NumPy array\n",
        "y_test_np = np.array(y_test)\n",
        "\n",
        "# Count the number of 1s and 0s in y_pred and y_test\n",
        "num_ones_pred = np.count_nonzero(y_pred_np == 1)\n",
        "num_zeros_pred = np.count_nonzero(y_pred_np == 0)\n",
        "\n",
        "num_ones_test = np.count_nonzero(y_test_np == 1)\n",
        "num_zeros_test = np.count_nonzero(y_test_np == 0)\n",
        "\n",
        "# Print the results\n",
        "print(\"Number of 1s in y_pred:\", num_ones_pred)\n",
        "print(\"Number of 0s in y_pred:\", num_zeros_pred)\n",
        "\n",
        "print(\"Number of 1s in y_test:\", num_ones_test)\n",
        "print(\"Number of 0s in y_test:\", num_zeros_test)\n",
        "\n",
        "print('Transformer Results:')\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "print('Roc:', metrics.roc_auc_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of 1s in y_pred: 1615\n",
            "Number of 0s in y_pred: 1385\n",
            "Number of 1s in y_test: 1478\n",
            "Number of 0s in y_test: 1522\n",
            "Transformer Results:\n",
            "Accuracy: 0.8663333333333333\n",
            "[[1253  269]\n",
            " [ 132 1346]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.90      0.82      0.86      1522\n",
            "         1.0       0.83      0.91      0.87      1478\n",
            "\n",
            "    accuracy                           0.87      3000\n",
            "   macro avg       0.87      0.87      0.87      3000\n",
            "weighted avg       0.87      0.87      0.87      3000\n",
            "\n",
            "Roc: 0.8669744958471066\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lqrrf7J1RPVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jg7YpM4PiHxF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ca0dc8e-b3a4-4119-b37d-6348752b8817"
      },
      "source": [
        "#load data\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from pandas import read_csv\n",
        "\n",
        "output_window = 1\n",
        "\n",
        "def get_data():\n",
        "    data = []\n",
        "    features = []\n",
        "    location = []\n",
        "    label = []\n",
        "    series = read_csv('Rain/data_total_prep2.csv', sep=',', header=None, low_memory=False, keep_default_na=False).to_numpy()\n",
        "\n",
        "    for i in range(len(series)):\n",
        "        if i == 0:\n",
        "            continue\n",
        "\n",
        "        # if '' in series[i]:\n",
        "        #   continue\n",
        "\n",
        "        line = series[i][2:-14]\n",
        "        line = [float(_) if _ != '' else -1 for _ in line]\n",
        "        line = [int(j) for j in line]\n",
        "\n",
        "        data.append(line)\n",
        "\n",
        "        f = series[i][-14:-1]\n",
        "        f = [float(_) if _ != '' else -1 for _ in f]\n",
        "        f = [int(_) for _ in f]\n",
        "\n",
        "        features.append(f)\n",
        "\n",
        "        label.append(int(float(series[i][-1])))\n",
        "\n",
        "    data = np.asarray(data)\n",
        "    features = np.asarray(features)\n",
        "    label = np.asarray(label)\n",
        "\n",
        "    data_ = []\n",
        "    features_ = []\n",
        "    for i in range(len(data)):\n",
        "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "        x = data[i]\n",
        "        x = scaler.fit_transform(np.array(x).reshape(-1, 1)).reshape(-1)\n",
        "        data_.append(x)\n",
        "\n",
        "        features_.append(scaler.fit_transform(np.array(features[i]).reshape(-1, 1)).reshape(-1))\n",
        "\n",
        "    input_data = torch.FloatTensor(data_)\n",
        "    label = torch.FloatTensor(label)\n",
        "    features = torch.FloatTensor(features_)\n",
        "\n",
        "    samples = int(len(input_data)*0.7)\n",
        "    x_train = input_data[:samples]\n",
        "    x_test = input_data[samples:]\n",
        "\n",
        "    y_train = label[:samples]\n",
        "    y_test = label[samples:]\n",
        "\n",
        "    ftr_train = features[:samples]\n",
        "    ftr_test = features[samples:]\n",
        "\n",
        "    return x_train, y_train, ftr_train, x_test, y_test, ftr_test\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    x_train, y_train, ftr_train, x_test, y_test, ftr_test = get_data()\n",
        "    print(x_train.shape)\n",
        "    print(y_train.shape)\n",
        "    print(ftr_train.shape)\n",
        "\n",
        "    print(x_test.shape)\n",
        "    print(y_test.shape)\n",
        "    print(ftr_test.shape)\n",
        "\n",
        "    pass\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([7000, 131])\n",
            "torch.Size([7000])\n",
            "torch.Size([7000, 13])\n",
            "torch.Size([3000, 131])\n",
            "torch.Size([3000])\n",
            "torch.Size([3000, 13])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from pandas import read_csv\n",
        "import pandas as pd\n",
        "\n",
        "output_window = 1\n",
        "\n",
        "def get_data():\n",
        "    data = []\n",
        "    features = []\n",
        "    location = []\n",
        "    label = []\n",
        "\n",
        "    # Load npy files\n",
        "    df = read_csv('Rain/data_total_prep2.csv', sep=',', header=None, low_memory=False, keep_default_na=False)\n",
        "\n",
        "    # Convert the DataFrame to a NumPy array\n",
        "    series = df.to_numpy()\n",
        "\n",
        "    for i in range(len(df)):\n",
        "        if i == 0:\n",
        "            continue\n",
        "\n",
        "        line = series[i][1:-14]\n",
        "        line = [float(_) if _ != '' else -1 for _ in line]\n",
        "        line = [int(j) for j in line]\n",
        "\n",
        "        data.append(line)\n",
        "\n",
        "        f = series[i][-14:-1]\n",
        "        f = [float(_) if _ != '' else -1 for _ in f]\n",
        "        f = [int(_) for _ in f]\n",
        "\n",
        "        features.append(f)\n",
        "\n",
        "        label.append(int(float(series[i][-1])))\n",
        "\n",
        "    data = np.asarray(data)\n",
        "    features = np.asarray(features)\n",
        "    label = np.asarray(label)\n",
        "\n",
        "    data_ = []\n",
        "    features_ = []\n",
        "    for i in range(len(data)):\n",
        "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "        x = data[i]\n",
        "        x = scaler.fit_transform(np.array(x).reshape(-1, 1)).reshape(-1)\n",
        "        data_.append(x)\n",
        "\n",
        "        features_.append(scaler.fit_transform(np.array(features[i]).reshape(-1, 1)).reshape(-1))\n",
        "\n",
        "    input_data = torch.FloatTensor(data_)\n",
        "    label = torch.FloatTensor(label)\n",
        "    features = torch.FloatTensor(features_)\n",
        "\n",
        "    # Shuffle the data before splitting into train and test sets\n",
        "    x_train, x_test, y_train, y_test, ftr_train, ftr_test = train_test_split(\n",
        "        input_data, label, features, test_size=0.3, random_state=42, shuffle=True)\n",
        "\n",
        "    return x_train, y_train, ftr_train, x_test, y_test, ftr_test\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    x_train, y_train, ftr_train, x_test, y_test, ftr_test = get_data()\n",
        "    print(x_train.shape)\n",
        "    print(x_train)\n",
        "    print(y_train.shape)\n",
        "    print(ftr_train.shape)\n",
        "\n",
        "    print(x_test.shape)\n",
        "    print(y_test.shape)\n",
        "    print(ftr_test.shape)\n",
        "\n",
        "    print(ftr_all.shape)\n",
        "\n",
        "    pass\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c4e090d-32c8-428c-c9f9-6ad821f9db35",
        "id": "ASMaNtzuZkA4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([7000, 132])\n",
            "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.5036, 0.2628, 0.2555],\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.4706, 0.3235],\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 0.7534, 1.0000, 0.6027],\n",
            "        ...,\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 0.5574, 0.3770, 0.2869],\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 0.0139, 0.0278, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 0.9583, 0.5104, 0.4896]])\n",
            "torch.Size([7000])\n",
            "torch.Size([7000, 13])\n",
            "torch.Size([3000, 132])\n",
            "torch.Size([3000])\n",
            "torch.Size([3000, 13])\n",
            "torch.Size([10000, 13])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypNWKz8Rjz7u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1ed50c9-213e-4329-b398-9b5fb81053a3"
      },
      "source": [
        "##Transformer\n",
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "import sys\n",
        "import math\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, max_len=5000,**block_args):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        pe.requires_grad = True\n",
        "        self.register_buffer('pe', pe)\n",
        "        #self.layers = nn.ModuleList([EncoderBlock(**block_args) for _ in range(num_layers)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:x.size(0), :]\n",
        "\n",
        "    def get_attention_maps(self, x, mask=None):\n",
        "        attention_maps = []\n",
        "        for l in self.layers:\n",
        "            _, attn_map = l.self_attn(x, mask=mask, return_attention=True)\n",
        "            attention_maps.append(attn_map)\n",
        "            x = l(x)\n",
        "        return attention_maps\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, input_size, feature_size=250,num_layers=1,dropout=0.1):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.src_mask = None\n",
        "        self.pos_encoder = PositionalEncoding(feature_size)\n",
        "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=feature_size, nhead=10, dropout=dropout)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
        "\n",
        "        self.layer = nn.Linear(feature_size,1)\n",
        "        self.layer1 = nn.Linear(input_size, 200)\n",
        "        self.layer2 = nn.Linear(200, 100)\n",
        "        self.layer3 = nn.Linear(100, 1)\n",
        "\n",
        "        self.last_layer = nn.Sigmoid()\n",
        "\n",
        "\n",
        "    def forward(self, src, ftr):\n",
        "        if self.src_mask is None or self.src_mask.size(0) != len(src):\n",
        "            mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
        "            self.src_mask = mask\n",
        "\n",
        "        src = self.pos_encoder(src)\n",
        "        hidden = self.transformer_encoder(src,self.src_mask)\n",
        "\n",
        "        ftr = torch.reshape(ftr, (ftr.shape[0], ftr.shape[1], 1))\n",
        "        ftr = ftr.expand(ftr.shape[0], ftr.shape[1], hidden.shape[2])\n",
        "\n",
        "        hidden = torch.cat((hidden, ftr), 0)\n",
        "\n",
        "        output = self.layer(hidden)\n",
        "\n",
        "        output = torch.squeeze(output)\n",
        "        output = output.transpose(0, 1)\n",
        "\n",
        "        output = self.layer1(output)\n",
        "        output = self.layer2(output)\n",
        "        output = self.layer3(output)\n",
        "\n",
        "        output = self.last_layer(output)\n",
        "        return output\n",
        "\n",
        "    def _generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "        return mask\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    arg_parser = argparse.ArgumentParser()\n",
        "    arg_parser.add_argument('--mode', choices=['train', 'infer'],\\\n",
        "        default='train',help='Run mode')\n",
        "    arg_parser.add_argument('--epoch', default='200', type=int)\n",
        "    arg_parser.add_argument('--batch_size', default='32', type=int)\n",
        "    args = arg_parser.parse_args(args=['--mode', 'train'])\n",
        "    args = arg_parser.parse_args(args=['--epoch', '200'])\n",
        "    args = arg_parser.parse_args(args=['--batch_size', '32'])\n",
        "\n",
        "    model_path = PATH + 'MODEL1/model_all_transformer_12.pt'\n",
        "\n",
        "    X_train, y_train, FTR_train, X_test, y_test, FTR_test = get_data()\n",
        "\n",
        "    print(X_train.shape)\n",
        "    print(y_train.shape)\n",
        "    print(X_test.shape)\n",
        "    print(y_test.shape)\n",
        "\n",
        "    model = Transformer(input_size = X_train.shape[1] + FTR_train.shape[1])\n",
        "    #loss_function = nn.MSELoss()\n",
        "    loss_function = nn.BCELoss()\n",
        "\n",
        "    #map = model.get_attention_maps(X_train)\n",
        "    #print(map)\n",
        "\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.02)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.98)\n",
        "\n",
        "    num_batch = int(len(y_train)/args.batch_size) + 1\n",
        "\n",
        "    num_batch_test = int(len(y_test)/args.batch_size) + 1\n",
        "\n",
        "    last_acc = 0.0\n",
        "\n",
        "    if args.mode == 'train':\n",
        "\n",
        "        for epoch in range(args.epoch):\n",
        "\n",
        "            acc = []\n",
        "            total_loss = 0\n",
        "\n",
        "            acc_test = []\n",
        "\n",
        "            model.to(device)\n",
        "\n",
        "            for i in range(num_batch):\n",
        "                sys.stdout.write('\\r{0}/{1}'.format(i, num_batch))\n",
        "                st = i * args.batch_size\n",
        "                ed = min((i+1) * args.batch_size, len(y_train))\n",
        "\n",
        "                x = X_train[st:ed]\n",
        "                x = x.transpose(0, 1)\n",
        "                x = torch.reshape(x, (x.shape[0], x.shape[1], 1))\n",
        "                x = x.to(device)\n",
        "\n",
        "                ftr = FTR_train[st:ed]\n",
        "                ftr = ftr.transpose(0, 1)\n",
        "                ftr = torch.reshape(ftr, (ftr.shape[0], ftr.shape[1], 1))\n",
        "                ftr = ftr.to(device)\n",
        "\n",
        "                label = y_train[st:ed]\n",
        "                label = label.to(device)\n",
        "\n",
        "                model.zero_grad()\n",
        "\n",
        "                output = model(x, ftr)\n",
        "                predict = torch.squeeze(output)\n",
        "\n",
        "                loss = loss_function(predict, label)\n",
        "\n",
        "                acc.append(torch.sum(predict.gt(0.5) == label))\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                total_loss += loss.item()\n",
        "\n",
        "            for i in range(num_batch_test):\n",
        "                st = i * args.batch_size\n",
        "                ed = min((i+1) * args.batch_size, len(y_test))\n",
        "\n",
        "                x_test = X_test[st:ed]\n",
        "                x_test = x_test.transpose(0, 1)\n",
        "                x_test = torch.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
        "                x_test = x_test.to(device)\n",
        "\n",
        "                ftr_test = FTR_test[st:ed]\n",
        "                ftr_test = ftr_test.transpose(0, 1)\n",
        "                ftr_test = torch.reshape(ftr_test, (ftr_test.shape[0], ftr_test.shape[1], 1))\n",
        "                ftr_test = ftr_test.to(device)\n",
        "\n",
        "                label_test = y_test[st:ed]\n",
        "                label_test = label_test.to(device)\n",
        "\n",
        "\n",
        "                output_test = model(x_test, ftr_test)\n",
        "                predict_test = torch.squeeze(output_test)\n",
        "                acc_test.append(torch.sum(predict_test.gt(0.5) == label_test))\n",
        "\n",
        "            total_loss /= len(y_train)\n",
        "            acc = sum(acc)*1.0/len(y_train)\n",
        "\n",
        "            acc_test = sum(acc_test)*1.0/len(y_test)\n",
        "            if epoch%10 == 0 or epoch == args.epoch - 1:\n",
        "              print('\\nEpoch: ', epoch)\n",
        "              print('\\nTraining set: Loss {0:.4f}. Acc {1:.4f}.\\nTest set: Acc {2:.4f}.'.format(total_loss, acc, acc_test))\n",
        "\n",
        "            scheduler.step()\n",
        "\n",
        "            if acc_test > last_acc:\n",
        "                torch.save(model.cpu(), model_path)\n",
        "                last_acc = acc_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([7000, 132])\n",
            "torch.Size([7000])\n",
            "torch.Size([3000, 132])\n",
            "torch.Size([3000])\n",
            "218/219\n",
            "Epoch:  0\n",
            "\n",
            "Training set: Loss 0.0217. Acc 0.5251.\n",
            "Test set: Acc 0.5073.\n",
            "218/219\n",
            "Epoch:  10\n",
            "\n",
            "Training set: Loss 0.0150. Acc 0.7537.\n",
            "Test set: Acc 0.7297.\n",
            "218/219\n",
            "Epoch:  20\n",
            "\n",
            "Training set: Loss 0.0136. Acc 0.7834.\n",
            "Test set: Acc 0.7750.\n",
            "218/219\n",
            "Epoch:  30\n",
            "\n",
            "Training set: Loss 0.0128. Acc 0.7999.\n",
            "Test set: Acc 0.7910.\n",
            "218/219\n",
            "Epoch:  40\n",
            "\n",
            "Training set: Loss 0.0122. Acc 0.8127.\n",
            "Test set: Acc 0.8040.\n",
            "218/219\n",
            "Epoch:  50\n",
            "\n",
            "Training set: Loss 0.0118. Acc 0.8183.\n",
            "Test set: Acc 0.8133.\n",
            "218/219\n",
            "Epoch:  60\n",
            "\n",
            "Training set: Loss 0.0115. Acc 0.8276.\n",
            "Test set: Acc 0.8220.\n",
            "218/219\n",
            "Epoch:  70\n",
            "\n",
            "Training set: Loss 0.0112. Acc 0.8354.\n",
            "Test set: Acc 0.8223.\n",
            "218/219\n",
            "Epoch:  80\n",
            "\n",
            "Training set: Loss 0.0111. Acc 0.8387.\n",
            "Test set: Acc 0.8283.\n",
            "218/219\n",
            "Epoch:  90\n",
            "\n",
            "Training set: Loss 0.0109. Acc 0.8373.\n",
            "Test set: Acc 0.8250.\n",
            "218/219\n",
            "Epoch:  100\n",
            "\n",
            "Training set: Loss 0.0108. Acc 0.8441.\n",
            "Test set: Acc 0.8330.\n",
            "218/219\n",
            "Epoch:  110\n",
            "\n",
            "Training set: Loss 0.0106. Acc 0.8439.\n",
            "Test set: Acc 0.8380.\n",
            "218/219\n",
            "Epoch:  120\n",
            "\n",
            "Training set: Loss 0.0106. Acc 0.8473.\n",
            "Test set: Acc 0.8343.\n",
            "218/219\n",
            "Epoch:  130\n",
            "\n",
            "Training set: Loss 0.0105. Acc 0.8486.\n",
            "Test set: Acc 0.8333.\n",
            "218/219\n",
            "Epoch:  140\n",
            "\n",
            "Training set: Loss 0.0104. Acc 0.8521.\n",
            "Test set: Acc 0.8377.\n",
            "218/219\n",
            "Epoch:  150\n",
            "\n",
            "Training set: Loss 0.0104. Acc 0.8490.\n",
            "Test set: Acc 0.8353.\n",
            "218/219\n",
            "Epoch:  160\n",
            "\n",
            "Training set: Loss 0.0104. Acc 0.8460.\n",
            "Test set: Acc 0.8353.\n",
            "218/219\n",
            "Epoch:  170\n",
            "\n",
            "Training set: Loss 0.0102. Acc 0.8514.\n",
            "Test set: Acc 0.8350.\n",
            "218/219\n",
            "Epoch:  180\n",
            "\n",
            "Training set: Loss 0.0104. Acc 0.8443.\n",
            "Test set: Acc 0.8350.\n",
            "218/219\n",
            "Epoch:  190\n",
            "\n",
            "Training set: Loss 0.0103. Acc 0.8500.\n",
            "Test set: Acc 0.8423.\n",
            "218/219\n",
            "Epoch:  199\n",
            "\n",
            "Training set: Loss 0.0103. Acc 0.8503.\n",
            "Test set: Acc 0.8363.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mPB6zsErRUFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XvOYlCNjMer",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a8f176c-d534-495d-aec0-43e367d8e449"
      },
      "source": [
        "#Transformer evaluation\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "model_path = PATH + 'MODEL1/model_all_transformer_12.pt'\n",
        "model = torch.load(model_path)\n",
        "model.to(device)\n",
        "acc_test = []\n",
        "y_pred = []\n",
        "\n",
        "for i in range(num_batch_test):\n",
        "    st = i * args.batch_size\n",
        "    ed = min((i+1) * args.batch_size, len(y_test))\n",
        "\n",
        "    x_test = X_test[st:ed]\n",
        "    x_test = x_test.transpose(0, 1)\n",
        "    x_test = torch.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
        "    x_test = x_test.to(device)\n",
        "\n",
        "    ftr_test = FTR_test[st:ed]\n",
        "    ftr_test = ftr_test.transpose(0, 1)\n",
        "    ftr_test = torch.reshape(ftr_test, (ftr_test.shape[0], ftr_test.shape[1], 1))\n",
        "    ftr_test = ftr_test.to(device)\n",
        "\n",
        "    label_test = y_test[st:ed]\n",
        "    label_test = label_test.to(device)\n",
        "\n",
        "\n",
        "    output_test = model(x_test, ftr_test)\n",
        "    predict_test = torch.squeeze(output_test)\n",
        "    y_pred += predict_test.gt(0.5)\n",
        "\n",
        "y_pred = list(map(float, y_pred))\n",
        "y_pred = np.asarray(y_pred)\n",
        "y_pred = torch.FloatTensor(y_pred)\n",
        "\n",
        "print('Transformer Results:')\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(metrics.roc_auc_score(y_test, y_pred))\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "\n",
        "#fpr, tpr, threshold = metrics.roc_curve(y_test, y_pred)\n",
        "#roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "#import matplotlib.pyplot as plt\n",
        "\n",
        "#plt.title('Receiver Operating Characteristic')\n",
        "#plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "#plt.legend(loc = 'lower right')\n",
        "#plt.plot([0, 1], [0, 1],'r--',label='Sample Label Red')\n",
        "#plt.xlim([0, 1])\n",
        "#plt.ylim([0, 1])\n",
        "#plt.ylabel('True Positive Rate')\n",
        "#plt.xlabel('False Positive Rate')\n",
        "#plt.savefig(PATH+\"roc.png\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformer Results:\n",
            "Accuracy: 0.8346666666666667\n",
            "[[1249  273]\n",
            " [ 223 1255]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.85      0.82      0.83      1522\n",
            "         1.0       0.82      0.85      0.83      1478\n",
            "\n",
            "    accuracy                           0.83      3000\n",
            "   macro avg       0.83      0.83      0.83      3000\n",
            "weighted avg       0.84      0.83      0.83      3000\n",
            "\n",
            "0.834875591016023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jw1ykuOzEP-T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe9b4b52-749f-44e3-b05d-e36c157d6369"
      },
      "source": [
        "#MLP baseline\n",
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "import sys\n",
        "import math\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(MLP, self).__init__()\n",
        "        self.layer1 = nn.Linear(input_size, 200)\n",
        "        self.layer2 = nn.Linear(200, 100)\n",
        "        self.layer3 = nn.Linear(100, 1)\n",
        "\n",
        "        self.last_layer = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, src, ftr):\n",
        "        ftr = torch.reshape(ftr, (ftr.shape[0], ftr.shape[1], 1))\n",
        "        ftr = ftr.expand(ftr.shape[0], ftr.shape[1], src.shape[2])\n",
        "\n",
        "        hidden = torch.cat((src, ftr), 0)\n",
        "\n",
        "        output = torch.squeeze(hidden)\n",
        "        output = output.transpose(0, 1)\n",
        "\n",
        "        output = self.layer1(output)\n",
        "        output = self.layer2(output)\n",
        "        output = self.layer3(output)\n",
        "\n",
        "        output = self.last_layer(output)\n",
        "        return output\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    arg_parser = argparse.ArgumentParser()\n",
        "    arg_parser.add_argument('--mode', choices=['train', 'infer'],\\\n",
        "        default='train',help='Run mode')\n",
        "    arg_parser.add_argument('--epoch', default='60', type=int)\n",
        "    arg_parser.add_argument('--batch_size', default='32', type=int)\n",
        "    args = arg_parser.parse_args(args=['--mode', 'train'])\n",
        "    args = arg_parser.parse_args(args=['--epoch', '60'])\n",
        "    args = arg_parser.parse_args(args=['--batch_size', '32'])\n",
        "\n",
        "    model_path_mlp = PATH + 'MODEL1/model_mlp_temporal.pt'\n",
        "\n",
        "    X_train, y_train, FTR_train, X_test, y_test, FTR_test = get_data()\n",
        "\n",
        "    print(X_train.shape)\n",
        "    print(y_train.shape)\n",
        "    print(X_test.shape)\n",
        "    print(y_test.shape)\n",
        "\n",
        "    model = MLP(input_size = X_train.shape[1] + FTR_train.shape[1])\n",
        "    #loss_function = nn.MSELoss()\n",
        "    loss_function = nn.BCELoss()\n",
        "\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.98)\n",
        "\n",
        "    num_batch = int(len(y_train)/args.batch_size) + 1\n",
        "\n",
        "    num_batch_test = int(len(y_test)/args.batch_size) + 1\n",
        "\n",
        "    last_acc = 0.0\n",
        "\n",
        "    if args.mode == 'train':\n",
        "\n",
        "        for epoch in range(args.epoch):\n",
        "\n",
        "            acc = []\n",
        "            total_loss = 0\n",
        "\n",
        "            acc_test = []\n",
        "\n",
        "            model.to(device)\n",
        "\n",
        "            for i in range(num_batch):\n",
        "                sys.stdout.write('\\r{0}/{1}'.format(i, num_batch))\n",
        "                st = i * args.batch_size\n",
        "                ed = min((i+1) * args.batch_size, len(y_train))\n",
        "\n",
        "                x = X_train[st:ed]\n",
        "                x = x.transpose(0, 1)\n",
        "                x = torch.reshape(x, (x.shape[0], x.shape[1], 1))\n",
        "                x = x.to(device)\n",
        "\n",
        "                ftr = FTR_train[st:ed]\n",
        "                ftr = ftr.transpose(0, 1)\n",
        "                ftr = torch.reshape(ftr, (ftr.shape[0], ftr.shape[1], 1))\n",
        "                ftr = ftr.to(device)\n",
        "\n",
        "                label = y_train[st:ed]\n",
        "                label = label.to(device)\n",
        "\n",
        "                model.zero_grad()\n",
        "\n",
        "                output = model(x, ftr)\n",
        "                predict = torch.squeeze(output)\n",
        "\n",
        "                loss = loss_function(predict, label)\n",
        "\n",
        "                acc.append(torch.sum(predict.gt(0.5) == label))\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                total_loss += loss.item()\n",
        "\n",
        "            for i in range(num_batch_test):\n",
        "                st = i * args.batch_size\n",
        "                ed = min((i+1) * args.batch_size, len(y_test))\n",
        "\n",
        "                x_test = X_test[st:ed]\n",
        "                x_test = x_test.transpose(0, 1)\n",
        "                x_test = torch.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
        "                x_test = x_test.to(device)\n",
        "\n",
        "                ftr_test = FTR_test[st:ed]\n",
        "                ftr_test = ftr_test.transpose(0, 1)\n",
        "                ftr_test = torch.reshape(ftr_test, (ftr_test.shape[0], ftr_test.shape[1], 1))\n",
        "                ftr_test = ftr_test.to(device)\n",
        "\n",
        "                label_test = y_test[st:ed]\n",
        "                label_test = label_test.to(device)\n",
        "\n",
        "\n",
        "                output_test = model(x_test, ftr_test)\n",
        "                predict_test = torch.squeeze(output_test)\n",
        "                acc_test.append(torch.sum(predict_test.gt(0.5) == label_test))\n",
        "\n",
        "            total_loss /= len(y_train)\n",
        "            acc = sum(acc)*1.0/len(y_train)\n",
        "\n",
        "            acc_test = sum(acc_test)*1.0/len(y_test)\n",
        "            if epoch%10 == 0 or epoch == args.epoch - 1:\n",
        "              print('\\nEpoch: ', epoch)\n",
        "              print('\\nTraining set: Loss {0:.4f}. Acc {1:.4f}.\\nTest set: Acc {2:.4f}.'.format(total_loss, acc, acc_test))\n",
        "\n",
        "            scheduler.step()\n",
        "\n",
        "            if acc_test > last_acc:\n",
        "                torch.save(model.cpu(), model_path_mlp)\n",
        "                last_acc = acc_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([7000, 132])\n",
            "torch.Size([7000])\n",
            "torch.Size([3000, 132])\n",
            "torch.Size([3000])\n",
            "218/219\n",
            "Epoch:  0\n",
            "\n",
            "Training set: Loss 0.0216. Acc 0.5657.\n",
            "Test set: Acc 0.5167.\n",
            "218/219\n",
            "Epoch:  10\n",
            "\n",
            "Training set: Loss 0.0166. Acc 0.7480.\n",
            "Test set: Acc 0.7497.\n",
            "218/219\n",
            "Epoch:  20\n",
            "\n",
            "Training set: Loss 0.0142. Acc 0.7583.\n",
            "Test set: Acc 0.7553.\n",
            "218/219\n",
            "Epoch:  30\n",
            "\n",
            "Training set: Loss 0.0134. Acc 0.7853.\n",
            "Test set: Acc 0.7803.\n",
            "218/219\n",
            "Epoch:  40\n",
            "\n",
            "Training set: Loss 0.0129. Acc 0.8001.\n",
            "Test set: Acc 0.7943.\n",
            "218/219\n",
            "Epoch:  50\n",
            "\n",
            "Training set: Loss 0.0127. Acc 0.8044.\n",
            "Test set: Acc 0.7990.\n",
            "218/219\n",
            "Epoch:  59\n",
            "\n",
            "Training set: Loss 0.0125. Acc 0.8081.\n",
            "Test set: Acc 0.8017.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TDeGLMLwRck0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBWWoED6FY2z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c444182b-94dd-46ec-9adc-bad694d9c7e4"
      },
      "source": [
        "#MLP evaluation\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "model = torch.load(model_path_mlp)\n",
        "model.to(device)\n",
        "acc_test = []\n",
        "y_pred = []\n",
        "\n",
        "for i in range(num_batch_test):\n",
        "    st = i * args.batch_size\n",
        "    ed = min((i+1) * args.batch_size, len(y_test))\n",
        "\n",
        "    x_test = X_test[st:ed]\n",
        "    x_test = x_test.transpose(0, 1)\n",
        "    x_test = torch.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
        "    x_test = x_test.to(device)\n",
        "\n",
        "    ftr_test = FTR_test[st:ed]\n",
        "    ftr_test = ftr_test.transpose(0, 1)\n",
        "    ftr_test = torch.reshape(ftr_test, (ftr_test.shape[0], ftr_test.shape[1], 1))\n",
        "    ftr_test = ftr_test.to(device)\n",
        "\n",
        "    label_test = y_test[st:ed]\n",
        "    label_test = label_test.to(device)\n",
        "\n",
        "\n",
        "    output_test = model(x_test, ftr_test)\n",
        "    predict_test = torch.squeeze(output_test)\n",
        "    y_pred += predict_test.gt(0.5)\n",
        "\n",
        "y_pred = list(map(float, y_pred))\n",
        "y_pred = np.asarray(y_pred)\n",
        "y_pred = torch.FloatTensor(y_pred)\n",
        "\n",
        "print('MLP Results:')\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(metrics.roc_auc_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP Results:\n",
            "Accuracy: 0.802\n",
            "[[1168  354]\n",
            " [ 240 1238]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.83      0.77      0.80      1522\n",
            "         1.0       0.78      0.84      0.81      1478\n",
            "\n",
            "    accuracy                           0.80      3000\n",
            "   macro avg       0.80      0.80      0.80      3000\n",
            "weighted avg       0.80      0.80      0.80      3000\n",
            "\n",
            "0.8025148520837371\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMEfb2TsNPYw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0adce8b0-0af8-4d5a-cf6e-d7cee9869aac"
      },
      "source": [
        "#LSTM baseline\n",
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "import sys\n",
        "import math\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_size, feature_size=250,num_layers=1,dropout=0.1):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.layer1 = nn.LSTM(input_size, 50)\n",
        "        self.layer2 = nn.Linear(50, 1)\n",
        "\n",
        "        self.last_layer = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, src, ftr):\n",
        "\n",
        "        ftr = torch.reshape(ftr, (ftr.shape[0], ftr.shape[1], 1))\n",
        "        ftr = ftr.expand(ftr.shape[0], ftr.shape[1], src.shape[2])\n",
        "\n",
        "        hidden = torch.cat((src, ftr), 0)\n",
        "        hidden = hidden.transpose(1, 2)\n",
        "        hidden = hidden.transpose(0, 2)\n",
        "\n",
        "        hidden, (hn, cn) = self.layer1(hidden)\n",
        "        output = self.layer2(hidden)\n",
        "\n",
        "        output = self.last_layer(output)\n",
        "        return output\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    arg_parser = argparse.ArgumentParser()\n",
        "    arg_parser.add_argument('--mode', choices=['train', 'infer'],\\\n",
        "        default='train',help='Run mode')\n",
        "    arg_parser.add_argument('--epoch', default='40', type=int)\n",
        "    arg_parser.add_argument('--batch_size', default='32', type=int)\n",
        "    args = arg_parser.parse_args(args=['--mode', 'train'])\n",
        "    args = arg_parser.parse_args(args=['--epoch', '40'])\n",
        "    args = arg_parser.parse_args(args=['--batch_size', '32'])\n",
        "\n",
        "    model_path_lstm = PATH + 'MODEL1/model_lstm.pt'\n",
        "\n",
        "    X_train, y_train, FTR_train, X_test, y_test, FTR_test = get_data()\n",
        "\n",
        "    print(X_train.shape)\n",
        "    print(y_train.shape)\n",
        "    print(X_test.shape)\n",
        "    print(y_test.shape)\n",
        "\n",
        "    model = LSTM(input_size = X_train.shape[1] + FTR_train.shape[1])\n",
        "    #loss_function = nn.MSELoss()\n",
        "    loss_function = nn.BCELoss()\n",
        "\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.98)\n",
        "\n",
        "    num_batch = int(len(y_train)/args.batch_size) + 1\n",
        "\n",
        "    num_batch_test = int(len(y_test)/args.batch_size) + 1\n",
        "\n",
        "    last_acc = 0.0\n",
        "\n",
        "    if args.mode == 'train':\n",
        "\n",
        "        for epoch in range(args.epoch):\n",
        "\n",
        "            acc = []\n",
        "            total_loss = 0\n",
        "\n",
        "            acc_test = []\n",
        "\n",
        "            model.to(device)\n",
        "\n",
        "            for i in range(num_batch):\n",
        "                sys.stdout.write('\\r{0}/{1}'.format(i, num_batch))\n",
        "                st = i * args.batch_size\n",
        "                ed = min((i+1) * args.batch_size, len(y_train))\n",
        "\n",
        "                x = X_train[st:ed]\n",
        "                x = x.transpose(0, 1)\n",
        "                x = torch.reshape(x, (x.shape[0], x.shape[1], 1))\n",
        "                x = x.to(device)\n",
        "\n",
        "                ftr = FTR_train[st:ed]\n",
        "                ftr = ftr.transpose(0, 1)\n",
        "                ftr = torch.reshape(ftr, (ftr.shape[0], ftr.shape[1], 1))\n",
        "                ftr = ftr.to(device)\n",
        "\n",
        "                label = y_train[st:ed]\n",
        "                label = label.to(device)\n",
        "\n",
        "                model.zero_grad()\n",
        "\n",
        "                output = model(x, ftr)\n",
        "                predict = torch.squeeze(output)\n",
        "\n",
        "                loss = loss_function(predict, label)\n",
        "\n",
        "                acc.append(torch.sum(predict.gt(0.5) == label))\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                total_loss += loss.item()\n",
        "\n",
        "            for i in range(num_batch_test):\n",
        "                st = i * args.batch_size\n",
        "                ed = min((i+1) * args.batch_size, len(y_test))\n",
        "\n",
        "                x_test = X_test[st:ed]\n",
        "                x_test = x_test.transpose(0, 1)\n",
        "                x_test = torch.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
        "                x_test = x_test.to(device)\n",
        "\n",
        "                ftr_test = FTR_test[st:ed]\n",
        "                ftr_test = ftr_test.transpose(0, 1)\n",
        "                ftr_test = torch.reshape(ftr_test, (ftr_test.shape[0], ftr_test.shape[1], 1))\n",
        "                ftr_test = ftr_test.to(device)\n",
        "\n",
        "                label_test = y_test[st:ed]\n",
        "                label_test = label_test.to(device)\n",
        "\n",
        "\n",
        "                output_test = model(x_test, ftr_test)\n",
        "                predict_test = torch.squeeze(output_test)\n",
        "                acc_test.append(torch.sum(predict_test.gt(0.5) == label_test))\n",
        "\n",
        "            total_loss /= len(y_train)\n",
        "            acc = sum(acc)*1.0/len(y_train)\n",
        "\n",
        "            acc_test = sum(acc_test)*1.0/len(y_test)\n",
        "            if epoch%10 == 0 or epoch == args.epoch - 1:\n",
        "              print('\\nEpoch: ', epoch)\n",
        "              print('\\nTraining set: Loss {0:.4f}. Acc {1:.4f}.\\nTest set: Acc {2:.4f}.'.format(total_loss, acc, acc_test))\n",
        "\n",
        "            scheduler.step()\n",
        "\n",
        "            if acc_test > last_acc:\n",
        "                torch.save(model.cpu(), model_path_lstm)\n",
        "                last_acc = acc_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([7000, 132])\n",
            "torch.Size([7000])\n",
            "torch.Size([3000, 132])\n",
            "torch.Size([3000])\n",
            "218/219\n",
            "Epoch:  0\n",
            "\n",
            "Training set: Loss 0.0214. Acc 0.5570.\n",
            "Test set: Acc 0.5137.\n",
            "218/219\n",
            "Epoch:  10\n",
            "\n",
            "Training set: Loss 0.0135. Acc 0.7831.\n",
            "Test set: Acc 0.7853.\n",
            "218/219\n",
            "Epoch:  20\n",
            "\n",
            "Training set: Loss 0.0122. Acc 0.8139.\n",
            "Test set: Acc 0.8040.\n",
            "218/219\n",
            "Epoch:  30\n",
            "\n",
            "Training set: Loss 0.0115. Acc 0.8306.\n",
            "Test set: Acc 0.8170.\n",
            "218/219\n",
            "Epoch:  39\n",
            "\n",
            "Training set: Loss 0.0110. Acc 0.8376.\n",
            "Test set: Acc 0.8277.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLdkgDZRRy2R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b3c15e3-fe81-4a63-ba0d-dfee649bbb8b"
      },
      "source": [
        "#LSTM evaluation\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "model = torch.load(model_path_lstm)\n",
        "model.to(device)\n",
        "acc_test = []\n",
        "y_pred = []\n",
        "\n",
        "for i in range(num_batch_test):\n",
        "    st = i * args.batch_size\n",
        "    ed = min((i+1) * args.batch_size, len(y_test))\n",
        "\n",
        "    x_test = X_test[st:ed]\n",
        "    x_test = x_test.transpose(0, 1)\n",
        "    x_test = torch.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
        "    x_test = x_test.to(device)\n",
        "\n",
        "    ftr_test = FTR_test[st:ed]\n",
        "    ftr_test = ftr_test.transpose(0, 1)\n",
        "    ftr_test = torch.reshape(ftr_test, (ftr_test.shape[0], ftr_test.shape[1], 1))\n",
        "    ftr_test = ftr_test.to(device)\n",
        "\n",
        "    label_test = y_test[st:ed]\n",
        "    label_test = label_test.to(device)\n",
        "\n",
        "\n",
        "    output_test = model(x_test, ftr_test)\n",
        "    predict_test = torch.squeeze(output_test)\n",
        "    y_pred += predict_test.gt(0.5)\n",
        "\n",
        "y_pred = list(map(float, y_pred))\n",
        "y_pred = np.asarray(y_pred)\n",
        "y_pred = torch.FloatTensor(y_pred)\n",
        "\n",
        "print('LSTM Results:')\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(metrics.roc_auc_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM Results:\n",
            "Accuracy: 0.8276666666666667\n",
            "[[1164  358]\n",
            " [ 159 1319]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.76      0.82      1522\n",
            "         1.0       0.79      0.89      0.84      1478\n",
            "\n",
            "    accuracy                           0.83      3000\n",
            "   macro avg       0.83      0.83      0.83      3000\n",
            "weighted avg       0.83      0.83      0.83      3000\n",
            "\n",
            "0.8286026860889187\n"
          ]
        }
      ]
    }
  ]
}